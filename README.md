# Veri MadenciliÄŸi (Data Mining)

Veri madenciliÄŸi, bÃ¼yÃ¼k miktarda veri iÃ§erisindeki desenleri, bilgiyi ve anlamlÄ± iliÅŸkileri keÅŸfetmek iÃ§in kullanÄ±lan disiplinlerarasÄ± bir alanÄ±dÄ±r. Genellikle istatistiksel analiz, makine Ã¶ÄŸrenimi, yapay zeka ve veritabanÄ± yÃ¶netimi gibi alanlardan faydalanÄ±r. Veri madenciliÄŸi, veri iÃ§erisindeki gizli bilgileri ortaya Ã§Ä±karmak, tahminler yapmak ve karar destek sistemlerini gÃ¼Ã§lendirmek iÃ§in kullanÄ±lÄ±r.

ğŸ”—[Yapay Zekaya Giris Konu AnlatÄ±mÄ±](https://github.com/elifbeyzatok00/Data-Mining/blob/main/Yapay_Zekaya_Giris.ipynb)

Veri madenciliÄŸinin ana hedefleri ÅŸunlardÄ±r:

1. **Desen KeÅŸfi:** BÃ¼yÃ¼k veri kÃ¼melerindeki tekrarlanan desenleri ve iliÅŸkileri tespit etmek.

2. **Tahmin:** Gelecekteki olaylarÄ± veya deÄŸerleri tahmin etmek iÃ§in verilerden modeller oluÅŸturmak.

3. **Gruplama:** Benzer Ã¶zelliklere sahip veri noktalarÄ±nÄ± gruplayarak segmentasyon yapmak.

4. **YapÄ±sal Analiz:** Veri kÃ¼melerindeki yapÄ±nÄ±n ve iliÅŸkilerin anlaÅŸÄ±lmasÄ±nÄ± saÄŸlamak.

5. **Karar Destek:** Karar verme sÃ¼reÃ§lerini optimize etmek ve bilgiye dayalÄ± kararlar almak iÃ§in veri analizi ve modelleme kullanmak.

Veri madenciliÄŸi genellikle aÅŸaÄŸÄ±daki adÄ±mlarÄ± iÃ§eren bir sÃ¼reÃ§tir:

1. **Veri Toplama:** Ä°lgili veri kaynaklarÄ±ndan veri toplanmasÄ±.

2. **Veri HazÄ±rlÄ±ÄŸÄ±:** Veri temizleme, Ã¶niÅŸleme ve uygun formata getirme adÄ±mlarÄ±yla veri hazÄ±rlÄ±ÄŸÄ±nÄ±n yapÄ±lmasÄ±.

3. **Modelleme:** Makine Ã¶ÄŸrenimi, istatistiksel analiz ve diÄŸer teknikler kullanÄ±larak veriye model uydurma.

4. **DeÄŸerlendirme:** OluÅŸturulan modellerin performansÄ±nÄ±n deÄŸerlendirilmesi ve gerektiÄŸinde iyileÅŸtirilmesi.

5. **DaÄŸÄ±tÄ±m:** SonuÃ§larÄ±n yorumlanmasÄ± ve gerektiÄŸinde uygulamaya geÃ§irilmesi.

Veri madenciliÄŸi, birÃ§ok endÃ¼stride kullanÄ±lan bir araÃ§tÄ±r. Pazarlama, finans, saÄŸlÄ±k, perakende, telekomÃ¼nikasyon ve diÄŸer birÃ§ok sektÃ¶rde mÃ¼ÅŸteri davranÄ±ÅŸlarÄ±nÄ± anlama, risk analizi yapma, hedefleme ve segmentasyon gibi birÃ§ok farklÄ± alanda kullanÄ±lÄ±r.


### Makine Ã–ÄŸrenimi AlgoritmalarÄ±
![image](https://github.com/elifbeyzatok00/Data-Mining/assets/102792446/5ac8d548-7bb1-4265-9f73-c71dddcd268d)

Makine Ã¶ÄŸrenimi algoritmalarÄ±, veriye dayalÄ± Ã¶rÃ¼ntÃ¼leri tanÄ±mlamak, tahminler yapmak veya kararlar vermek iÃ§in kullanÄ±lan matematiksel modellerdir. Bu algoritmalar, genellikle Ã¶ÄŸrenme sÃ¼recinde veriye adapte olarak performanslarÄ±nÄ± artÄ±rÄ±rlar. Ä°ÅŸte yaygÄ±n olarak kullanÄ±lan bazÄ± makine Ã¶ÄŸrenimi algoritmalarÄ± ve detaylarÄ±:

1. **Denetimli Ã–ÄŸrenme AlgoritmalarÄ±:**
   - **DoÄŸrusal Regresyon:** BaÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi modellemek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, gelir ve harcama arasÄ±ndaki iliÅŸkiyi inceleyebilirsiniz.
   - **Lojistik Regresyon:** SÄ±nÄ±flandÄ±rma problemleri iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir e-postanÄ±n spam olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±labilir.
   - **Karar AÄŸaÃ§larÄ±:** Karar aÄŸaÃ§larÄ± veri kÃ¼mesini sÄ±nÄ±flandÄ±rmak veya regresyon yapmak iÃ§in aÄŸaÃ§ benzeri bir yapÄ± kullanÄ±r. Basit ve yorumlanabilir modeller saÄŸlarlar.
   - **Destek VektÃ¶r Makineleri (SVM):** Bir veri kÃ¼mesini sÄ±nÄ±flandÄ±rmak veya regresyon yapmak iÃ§in kullanÄ±lan bir algoritmadÄ±r. Belirli bir hiperdÃ¼zlemi oluÅŸturarak sÄ±nÄ±flar arasÄ±ndaki en geniÅŸ boÅŸluÄŸu (margin) maksimize etmeye Ã§alÄ±ÅŸÄ±r.
   - **K-En YakÄ±n KomÅŸu (KNN):** Bir veri noktasÄ±nÄ± etiketlemek iÃ§in yakÄ±ndaki veri noktalarÄ±nÄ±n Ã§oÄŸunluÄŸuna dayanÄ±r. Bu algoritma basit ve kullanÄ±mÄ± kolaydÄ±r.

   ğŸ”—[Denetimli Ã–ÄŸrenme Konu AnlatÄ±mÄ±](https://github.com/elifbeyzatok00/Data-Mining/blob/main/Denetimli_Ogrenme.pptx)

2. **Denetimsiz Ã–ÄŸrenme AlgoritmalarÄ±:**
   - **K-Means KÃ¼meleme:** Veri noktalarÄ±nÄ± belirli sayÄ±da kÃ¼meye (clusters) bÃ¶lmek iÃ§in kullanÄ±lÄ±r. Her kÃ¼menin merkezi, o kÃ¼menin veri noktalarÄ±nÄ±n ortalamasÄ±dÄ±r.
   - **HiyerarÅŸik KÃ¼meleme:** Bir veri kÃ¼mesini hiyerarÅŸik olarak kÃ¼meler halinde bÃ¶ler. Bu kÃ¼meler, bir aÄŸaÃ§ yapÄ±sÄ± oluÅŸturur ve farklÄ± dÃ¼zeylerdeki kÃ¼meleme seviyelerini gÃ¶sterir.
   - **Gauss KarÄ±ÅŸÄ±m Modelleme (GMM):** Her biri bir normal daÄŸÄ±lÄ±ma sahip olan birden fazla bileÅŸenin bir karÄ±ÅŸÄ±mÄ± olarak veriyi modellemek iÃ§in kullanÄ±lÄ±r. Genellikle veriye gizli bir yapÄ± uygular.
   - **Boyut Azaltma AlgoritmalarÄ±:** Boyut azaltma, veri setinin boyutunu azaltarak veriyi daha anlaÅŸÄ±labilir ve iÅŸlenebilir hale getirir. Ã–rneÄŸin, PCA (Principal Component Analysis) ve t-SNE (t-distributed Stochastic Neighbor Embedding) gibi algoritmalar kullanÄ±labilir.

3. **PekiÅŸtirmeli Ã–ÄŸrenme:**
   - **Q-Learning:** PekiÅŸtirmeli Ã¶ÄŸrenme iÃ§in temel bir algoritmadÄ±r. Bir ajanÄ±n Ã§evresiyle etkileÅŸimde bulunarak bir gÃ¶revi en iyi ÅŸekilde yerine getirmesini Ã¶ÄŸretir. Belli bir durumda alÄ±nabilecek aksiyonlarÄ±n deÄŸerini Ã¶ÄŸrenir.
   - **Policy Gradient:** Bu algoritma, doÄŸrudan bir politika fonksiyonunu optimize ederek ajanÄ±n davranÄ±ÅŸÄ±nÄ± iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±r. Genellikle derin Ã¶ÄŸrenmeyle birlikte kullanÄ±lÄ±r.

4. **Semi-Supervised Learning (YarÄ±-Denetimli Ã–ÄŸrenme):**
   - Hem etiketli hem de etiketlenmemiÅŸ verilerin kullanÄ±ldÄ±ÄŸÄ± bir Ã¶ÄŸrenme tÃ¼rÃ¼dÃ¼r. Bu yaklaÅŸÄ±m, sÄ±nÄ±flandÄ±rma veya regresyon problemlerinde etiketli verinin sÄ±nÄ±fÄ±nÄ± belirlemek iÃ§in kullanÄ±lÄ±rken, aynÄ± zamanda etiketlenmemiÅŸ veriden de yararlanÄ±r.

Bu, makine Ã¶ÄŸrenimi alanÄ±nda sÄ±kÃ§a kullanÄ±lan temel algoritmalarÄ±n bazÄ±larÄ±dÄ±r. Her bir algoritmanÄ±n farklÄ± avantajlarÄ±, dezavantajlarÄ± ve kullanÄ±m alanlarÄ± vardÄ±r. Veri setinizin boyutu, doÄŸasÄ± ve probleminizin gereksinimleri, hangi algoritmanÄ±n kullanÄ±lacaÄŸÄ±nÄ± belirlemede Ã¶nemli faktÃ¶rlerdir.

![image](https://github.com/elifbeyzatok00/Data-Mining/assets/102792446/e5a5f30d-cb7c-458c-9dd7-6977cd1ed21c)

![image](https://github.com/elifbeyzatok00/Data-Mining/assets/102792446/3e6e01e3-cd26-46f6-9c2b-f9dc3faa7804)

![image](https://github.com/elifbeyzatok00/Data-Mining/assets/102792446/4fdbdc4d-56a2-468d-be7d-d6fb5f9cbcc9)

ğŸ”—[Makine Ogrenmesi Modelleri Konu AnlatÄ±mÄ±](https://github.com/elifbeyzatok00/Data-Mining/blob/main/Makine_Ogrenmesi_Modelleri.ipynb)



### Derin Ã–ÄŸrenme AlgoritmalarÄ±

![image](https://github.com/elifbeyzatok00/Data-Mining/assets/102792446/19d08b58-61fa-4eee-a435-0ab94502544c)

Derin Ã¶ÄŸrenme, yapay sinir aÄŸlarÄ±nÄ±n Ã§ok katmanlÄ± ve karmaÅŸÄ±k yapÄ±larÄ±nÄ± kullanarak Ã¶ÄŸrenme sÃ¼recini gerÃ§ekleÅŸtiren bir makine Ã¶ÄŸrenimi alt dalÄ±dÄ±r. Ä°ÅŸte derin Ã¶ÄŸrenme algoritmalarÄ±nÄ±n baÅŸlÄ±ca tipleri ve detaylarÄ±:

1. **Yapay Sinir AÄŸlarÄ± (Artificial Neural Networks - ANN):**
   - Yapay sinir aÄŸlarÄ±, biyolojik sinir aÄŸlarÄ±nÄ± temel alan bir modeldir. Ã‡ok katmanlÄ± algÄ±layÄ±cÄ±lar, gizli katmanlar ve Ã§Ä±ktÄ± katmanlarÄ±ndan oluÅŸur.
   - Her katman, giriÅŸ verisini iÅŸleyerek daha karmaÅŸÄ±k Ã¶zellikler Ã¶ÄŸrenir.
   - Geriye yayÄ±lÄ±m algoritmasÄ± (Backpropagation), aÄŸÄ±n hatalarÄ±nÄ± azaltmak iÃ§in kullanÄ±lÄ±r.

   ğŸ”—[Yapay Sinir Aglari Giris Konu AnlatÄ±mÄ±](https://github.com/elifbeyzatok00/Data-Mining/blob/main/Yapay_Sinir_Aglari_Giris.ipynb)

2. **EvriÅŸimli Sinir AÄŸlarÄ± (Convolutional Neural Networks - CNN):**
   - GÃ¶rÃ¼ntÃ¼ ve video gibi yapÄ±sal veriler Ã¼zerinde baÅŸarÄ±yla Ã§alÄ±ÅŸan bir derin Ã¶ÄŸrenme modelidir.
   - FarklÄ± Ã¶zellik haritalarÄ± oluÅŸturmak iÃ§in evriÅŸim (convolution) ve havuzlama (pooling) katmanlarÄ±ndan oluÅŸur.
   - GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, nesne tespiti, yÃ¼z tanÄ±ma gibi gÃ¶revlerde etkilidir.

3. **Rekurrent Sinir AÄŸlarÄ± (Recurrent Neural Networks - RNN):**
   - Zamansal baÄŸÄ±mlÄ±lÄ±klarÄ± modellemek iÃ§in tasarlanmÄ±ÅŸtÄ±r. Ã–nceki zaman adÄ±mlarÄ±ndan gelen bilgileri hafÄ±zada saklarlar.
   - Ã–zellikle zaman serisi verileri, metin verileri ve doÄŸal dil iÅŸleme problemleri iÃ§in kullanÄ±lÄ±r.
   - Geleneksel RNN yapÄ±larÄ±nÄ±n yanÄ± sÄ±ra, uzun sÃ¼reli baÄŸÄ±mlÄ±lÄ±klarÄ± ele almak iÃ§in LSTM (Long Short-Term Memory) ve GRU (Gated Recurrent Unit) gibi modeller geliÅŸtirilmiÅŸtir.

4. **Ã–zerk KodlayÄ±cÄ±lar (Autoencoders):**
   - GiriÅŸ verisini sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ bir temsilasyona dÃ¶nÃ¼ÅŸtÃ¼ren ve ardÄ±ndan orijinal veriyi yeniden oluÅŸturan sinir aÄŸlarÄ±dÄ±r.
   - Unsupervised learning'de kullanÄ±lÄ±rlar ve veri setindeki gizli yapÄ±larÄ± Ã¶ÄŸrenmek iÃ§in kullanÄ±lÄ±rlar.
   - GÃ¼rÃ¼ltÃ¼lÃ¼ giriÅŸlere dayanÄ±klÄ± olabilirler ve boyut azaltma gibi gÃ¶revlerde kullanÄ±labilirler.

5. **Derin Ãœretim Modelleri (Generative Deep Learning Models):**
   - Veri setinden yeni Ã¶rnekler Ã¼reten modellerdir.
   - GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders) ve RBMs (Restricted Boltzmann Machines) gibi modellerle temsil edilirler.
   - Ã–rneÄŸin, GAN'lar gerÃ§ekÃ§i gÃ¶rÃ¼ntÃ¼ler Ã¼retmek iÃ§in kullanÄ±labilirler.

Bu algoritmalar, derin Ã¶ÄŸrenmenin temel yapÄ± taÅŸlarÄ±nÄ± oluÅŸturur. Her biri farklÄ± veri tÃ¼rlerini ve problemlerini ele almak iÃ§in tasarlanmÄ±ÅŸtÄ±r. GeliÅŸen teknoloji ve araÅŸtÄ±rmalarla, bu algoritmalarÄ±n yeni varyasyonlarÄ± ve iyileÅŸtirmeleri sÃ¼rekli olarak geliÅŸtirilmektedir.


### Veri madenciliÄŸinde kullanÄ±lan melez algoritmalar nelerdir? BirkaÃ§ algoritma birlikte nasÄ±l kullanÄ±lÄ±r? Ne amaÃ§la kullanÄ±lÄ±r?

Veri madenciliÄŸinde kullanÄ±lan melez algoritmalar, genellikle birbirini tamamlayÄ±cÄ± Ã¶zelliklere sahip olan farklÄ± algoritmalarÄ±n bir araya getirilmesiyle oluÅŸturulur. Bu, genellikle daha iyi sonuÃ§lar elde etmek, daha geniÅŸ bir veri yelpazesini kapsamak veya belirli zorluklarÄ± aÅŸmak iÃ§in yapÄ±lÄ±r. Ä°ÅŸte bazÄ± yaygÄ±n melez algoritmalar ve nasÄ±l kullanÄ±ldÄ±klarÄ±yla ilgili Ã¶rnekler:

1. **CNN+KNN (Convolutional Neural Network + K-Nearest Neighbors):**
   - **KullanÄ±m AmacÄ±:** GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma gibi gÃ¶revlerde yaygÄ±n olarak kullanÄ±lÄ±r. CNN, derin Ã¶ÄŸrenme modeli olarak Ã¶zellik Ã§Ä±karÄ±mÄ± yapar ve gÃ¶rsel veriyi temsil ederken, KNN ise bu Ã¶zellik vektÃ¶rlerini kullanarak sÄ±nÄ±flandÄ±rma iÅŸlemi yapar.
   - **NasÄ±l KullanÄ±lÄ±r:** Ä°lk adÄ±mda, bir CNN modeli eÄŸitilir ve gÃ¶rÃ¼ntÃ¼lerden Ã¶zellikler Ã§Ä±karÄ±lÄ±r. Daha sonra, bu Ã¶zellik vektÃ¶rleri KNN algoritmasÄ±yla birlikte kullanÄ±larak sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r. Yani, CNN modeli gÃ¶rÃ¼ntÃ¼leri Ã¶zellik vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve KNN, bu vektÃ¶rler Ã¼zerinde sÄ±nÄ±flandÄ±rma yapar.

2. **Random Forest + Gradient Boosting:**
   - **KullanÄ±m AmacÄ±:** Karar aÄŸaÃ§larÄ±na dayalÄ± yÃ¶ntemlerin kombinasyonu, tahmin ve sÄ±nÄ±flandÄ±rma problemlerinde genellikle daha yÃ¼ksek doÄŸruluk saÄŸlamak iÃ§in kullanÄ±lÄ±r.
   - **NasÄ±l KullanÄ±lÄ±r:** Ä°lk olarak, Random Forest algoritmasÄ± kullanÄ±larak birÃ§ok karar aÄŸacÄ± eÄŸitilir. Daha sonra, bu aÄŸaÃ§larÄ±n birleÅŸiminden bir tahmin yapÄ±lÄ±r. Bu tahminler, Gradient Boosting algoritmasÄ± kullanÄ±larak daha fazla rafine edilir. Gradient Boosting, Ã¶nceki tahminlerin hatalarÄ±nÄ± dÃ¼zelterek modeli gÃ¼Ã§lendirir.

3. **K-Means + DBSCAN:**
   - **KullanÄ±m AmacÄ±:** KÃ¼meleme problemlerinde kullanÄ±lÄ±r. K-Means, kÃ¼meleme iÅŸlemi iÃ§in merkezi yÃ¶ntemlerden biridir, ancak veri yapÄ±sÄ±nÄ±n gÃ¼rÃ¼ltÃ¼lÃ¼ veya karmaÅŸÄ±k olduÄŸu durumlarda yetersiz kalabilir. Bu durumda, DBSCAN gibi yoÄŸunluÄŸa dayalÄ± bir kÃ¼meleme algoritmasÄ± kullanÄ±labilir.
   - **NasÄ±l KullanÄ±lÄ±r:** Ä°lk olarak, K-Means algoritmasÄ± kullanÄ±larak kÃ¼meleme yapÄ±lÄ±r. Daha sonra, DBSCAN gibi bir yoÄŸunluk tabanlÄ± algoritma kullanÄ±larak kÃ¼meleme sonuÃ§larÄ± daha fazla rafine edilebilir. Ã–zellikle, K-Means'in oluÅŸturduÄŸu kÃ¼me merkezlerini baÅŸlangÄ±Ã§ noktasÄ± olarak kullanarak DBSCAN, daha kesin ve esnek kÃ¼meleme sonuÃ§larÄ± Ã¼retebilir.

Bu melez algoritmalar, belirli veri madenciliÄŸi problemlerine daha iyi Ã§Ã¶zÃ¼mler bulmak iÃ§in kullanÄ±lÄ±r. Bunlar, tek baÅŸÄ±na kullanÄ±lan algoritmalarÄ±n zayÄ±f noktalarÄ±nÄ± dengelemek ve farklÄ± Ã¶zelliklerin avantajlarÄ±nÄ± bir araya getirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

Ã–rnek:

Ä°ÅŸte bir Python kod Ã¶rneÄŸi, gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÃ§in CNN (Convolutional Neural Network) ile KNN (K-Nearest Neighbors) algoritmalarÄ±nÄ±n nasÄ±l bir araya getirilebileceÄŸini gÃ¶steriyor. Bu Ã¶rnekte, MNIST el yazÄ±sÄ± rakam veri kÃ¼mesini kullanacaÄŸÄ±z. Ä°lk olarak, CNN kullanarak el yazÄ±sÄ± rakamlarÄ± tanÄ±mak iÃ§in bir model eÄŸiteceÄŸiz ve ardÄ±ndan bu modelin Ã¶zellik vektÃ¶rlerini Ã§Ä±karacaÄŸÄ±z. Daha sonra, KNN algoritmasÄ± kullanÄ±larak bu Ã¶zellik vektÃ¶rlerini sÄ±nÄ±flandÄ±racaÄŸÄ±z.

```python
import numpy as np
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from keras.utils import to_categorical
from sklearn.neighbors import KNeighborsClassifier

# MNIST veri kÃ¼mesini yÃ¼kleme
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Veri kÃ¼mesini yeniden ÅŸekillendirme ve normalleÅŸtirme
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255

# Etiketleri ikili sÄ±nÄ±f matrislerine dÃ¶nÃ¼ÅŸtÃ¼rme
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# CNN modelini oluÅŸturma
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))

# Modeli derleme
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Modeli eÄŸitme
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))

# CNN modelinin Ã§Ä±ktÄ±larÄ±nÄ± kullanarak Ã¶zellik vektÃ¶rlerini Ã§Ä±karÄ±n
extractor = Sequential(model.layers[:-1])

X_train_features = extractor.predict(X_train)
X_test_features = extractor.predict(X_test)

# KNN modelini oluÅŸturma ve eÄŸitme
knn_model = KNeighborsClassifier(n_neighbors=3)
knn_model.fit(X_train_features, np.argmax(y_train, axis=1))

# Test verilerini kullanarak tahmin yapma
predictions = knn_model.predict(X_test_features)

# SonuÃ§larÄ± deÄŸerlendirme
accuracy = np.mean(predictions == np.argmax(y_test, axis=1))
print("Test doÄŸruluÄŸu:", accuracy)
```

Bu kod Ã¶rneÄŸinde, Ã¶ncelikle MNIST veri kÃ¼mesi yÃ¼klenir ve CNN modeli tanÄ±mlanÄ±r ve eÄŸitilir. Daha sonra, bu modelin Ã§Ä±ktÄ±larÄ±nÄ± kullanarak Ã¶zellik vektÃ¶rleri Ã§Ä±karÄ±lÄ±r ve KNN algoritmasÄ± kullanÄ±larak bu Ã¶zellik vektÃ¶rleri sÄ±nÄ±flandÄ±rÄ±lÄ±r. Son olarak, sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± deÄŸerlendirilir ve test doÄŸruluÄŸu hesaplanÄ±r.

### Veri madenciliÄŸi: Ã–znitelik seÃ§im alg ile kodlanacak tasarÄ±m adÄ±mlarÄ±nÄ± py ile kodlamaya dÃ¶nÃ¼ÅŸtÃ¼r. (Kod yok PSO entegrasyonu gerÃ§ekleÅŸtir)

Tabii, iÅŸte yorum satÄ±rlarÄ± ile birlikte tÃ¼m kodu tek bir hÃ¼crede:

```python
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Veri setini oluÅŸtur
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)

# Veri setini eÄŸitim ve test setlerine ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ParÃ§acÄ±k SÃ¼rÃ¼ Optimizasyonu (PSO) sÄ±nÄ±fÄ±nÄ± tanÄ±mla
class Particle:
    def __init__(self, num_features):
        # ParÃ§acÄ±k pozisyonunu rastgele seÃ§
        self.position = np.random.choice([0, 1], size=num_features)
        # ParÃ§acÄ±k hÄ±zÄ±nÄ± rastgele ata
        self.velocity = np.random.uniform(-1, 1, size=num_features)
        # ParÃ§acÄ±kÄ±n en iyi pozisyonunu ve skorunu tut
        self.best_position = self.position.copy()
        self.best_score = float('-inf')

class PSO:
    def __init__(self, num_particles, num_iterations):
        self.num_particles = num_particles
        self.num_iterations = num_iterations
        self.particles = []

    def optimize(self, X_train, X_test, y_train, y_test):
        num_features = X_train.shape[1]
        # ParÃ§acÄ±klarÄ± oluÅŸtur ve listeye ekle
        for _ in range(self.num_particles):
            particle = Particle(num_features)
            self.particles.append(particle)
        
        global_best_position = np.zeros(num_features)
        global_best_score = float('-inf')
        
        # PSO iterasyonlarÄ±nÄ± baÅŸlat
        for _ in range(self.num_iterations):
            # Her bir parÃ§acÄ±k iÃ§in optimize et
            for particle in self.particles:
                # SeÃ§ilmiÅŸ Ã¶zellikleri al
                selected_features = np.where(particle.position == 1)[0]
                if len(selected_features) == 0:
                    continue
                
                # SÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± oluÅŸtur ve eÄŸit
                clf = RandomForestClassifier(n_estimators=100, random_state=42)
                clf.fit(X_train[:, selected_features], y_train)
                # Test seti Ã¼zerinde tahmin yap
                y_pred = clf.predict(X_test[:, selected_features])
                score = accuracy_score(y_test, y_pred)
                
                # En iyi pozisyonu ve skoru gÃ¼ncelle
                if score > particle.best_score:
                    particle.best_score = score
                    particle.best_position = particle.position.copy()
                
                if score > global_best_score:
                    global_best_score = score
                    global_best_position = particle.position.copy()
            
            # HÄ±z ve pozisyon gÃ¼ncellemelerini hesapla
            for particle in self.particles:
                particle.velocity += 2 * np.random.random() * (particle.best_position - particle.position) + \
                                     2 * np.random.random() * (global_best_position - particle.position)
                particle.position += particle.velocity
                particle.position = np.clip(particle.position, 0, 1)
        
        return global_best_position

# PSO'yu kullanarak Ã¶znitelik seÃ§imini gerÃ§ekleÅŸtir ve sonuÃ§larÄ± yazdÄ±r
num_particles = 20
num_iterations = 50

pso = PSO(num_particles, num_iterations)
selected_features = pso.optimize(X_train, X_test, y_train, y_test)
print("Selected Features:", np.where(selected_features == 1)[0])
```

Bu kod parÃ§acÄ±klar arasÄ± optimizasyon kullanarak Ã¶znitelik seÃ§imi gerÃ§ekleÅŸtirir ve seÃ§ilen Ã¶zniteliklerin indekslerini yazdÄ±rÄ±r.

### Veri madenciliÄŸi: Ã–znitelik seÃ§im alg ile DDOS saldÄ±rÄ± tespiti ML modeli geliÅŸtir, veri setini Kaggleâ€™dan Ã§ek. (Kod yok PSO entegrasyonu gerÃ§ekleÅŸtir)

ğŸ”—[DDOS Attack Detection ML Model]()
